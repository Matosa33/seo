# ğŸ•¸ï¸ GÃ©nÃ©rateur de Cocons SÃ©mantiques

## ğŸ“‘ Table des matiÃ¨res
- [Ã€ propos](#-Ã -propos)
- [FonctionnalitÃ©s](#-fonctionnalitÃ©s)
- [Installation](#-installation)
- [Configuration](#-configuration)
- [Utilisation](#-utilisation)
- [Architecture](#-architecture)
- [API](#-api)
- [Tests](#-tests)
- [Performance](#-performance)
- [FAQ](#-faq)
- [Contribution](#-contribution)
- [Licence](#-licence)

## ğŸ¯ Ã€ propos

Le GÃ©nÃ©rateur de Cocons SÃ©mantiques est une application Python permettant de crÃ©er et d'analyser des cocons sÃ©mantiques pour le SEO. L'application utilise des algorithmes d'analyse sÃ©mantique avancÃ©s basÃ©s sur Word2Vec pour identifier les relations entre les mots-clÃ©s et suggÃ©rer des regroupements pertinents.

### Cas d'utilisation
- CrÃ©ation de structures de sites web optimisÃ©es pour le SEO
- Analyse de la pertinence sÃ©mantique des contenus
- Optimisation de la structure de navigation
- Planification de contenus web

## ğŸŒŸ FonctionnalitÃ©s

### Analyse sÃ©mantique
- Calcul de similaritÃ© entre mots-clÃ©s
- DÃ©tection des relations sÃ©mantiques
- Suggestions de mots-clÃ©s pertinents
- Clustering automatique

### Interface utilisateur
- Interface web interactive avec Streamlit
- Visualisation de graphes de relations
- Tableaux de bord dynamiques
- Export des donnÃ©es en JSON

### Performance
- Mise en cache intelligente des calculs
- Traitement parallÃ¨le
- Persistance des donnÃ©es
- Optimisation mÃ©moire

## ğŸš€ Installation

### PrÃ©requis
- Python 3.9+
- pip
- Environnement virtuel (recommandÃ©)

### Installation pas Ã  pas

1. Clonez le repository :
```bash
git clone https://github.com/votre-repo/cocon-semantique.git
cd cocon-semantique
```

2. CrÃ©ez et activez un environnement virtuel :
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
```

3. Installez les dÃ©pendances :
```bash
pip install -r requirements.txt
```

### DÃ©pendances principales
```txt
streamlit==1.31.1
pandas==2.2.0
numpy==1.26.4
plotly==5.18.0
networkx==3.2.1
gensim==4.3.2
joblib==1.3.2
tqdm==4.66.2
python-dotenv==1.0.1
```

## âš™ï¸ Configuration

### Structure des fichiers
```
app/
â”œâ”€â”€ __init__.py         # Initialisation du package
â”œâ”€â”€ app.py             # Interface Streamlit
â”œâ”€â”€ core.py            # Logique mÃ©tier
â”œâ”€â”€ utils.py           # Utilitaires
â”œâ”€â”€ cache/             # Cache des vecteurs et calculs
â””â”€â”€ requirements.txt   # DÃ©pendances
```

### Variables d'environnement
CrÃ©ez un fichier `.env` :
```env
CACHE_DIR=./cache
MODEL_DIM=50
LOG_LEVEL=INFO
```

## ğŸ“– Utilisation

### Lancement de l'application
```bash
streamlit run app/app.py
```

### Import des donnÃ©es
1. PrÃ©parez un fichier CSV avec les colonnes :
   - keyword : mots-clÃ©s
   - volume : volume de recherche mensuel

Exemple :
```csv
keyword,volume
marketing digital,1000
seo,800
rÃ©fÃ©rencement naturel,900
```

### Interface utilisateur

#### Barre latÃ©rale
- **Import** : Chargement des fichiers CSV
- **ParamÃ¨tres** :
  - Mode de suggestion (PrÃ©cis, Ã‰quilibrÃ©, Exploratoire)
  - Seuil de similaritÃ© (0.1 - 0.9)
  - Volume minimum
  - Nombre max de suggestions

#### Vue principale
- **SÃ©lecteur de mots-clÃ©s** : Liste filtrÃ©e des mots-clÃ©s
- **RÃ©seau sÃ©mantique** : Visualisation des relations
- **Gestionnaire de cocon** : Suggestions et groupes

### Export des donnÃ©es
- Format JSON avec mÃ©tadonnÃ©es
- Statistiques complÃ¨tes
- Relations sÃ©mantiques
- Clusters identifiÃ©s

## ğŸ—ï¸ Architecture

### Composants principaux

#### SemanticCore
```python
core = SemanticCore(
    model_dim=50,
    cache_dir='./cache',
    preload_common=True
)
```
GÃ¨re l'analyse sÃ©mantique et les calculs.

#### SemanticCocoonApp
```python
app = SemanticCocoonApp()
app.run()
```
Interface utilisateur et gestion des interactions.

### Flux de donnÃ©es
1. Import CSV â†’ Nettoyage â†’ Vectorisation
2. Analyse sÃ©mantique â†’ Cache â†’ Suggestions
3. Interface â†’ Visualisation â†’ Export

## ğŸ“š API

### Core API

```python
# Calcul de similaritÃ©
similarity = core.calculate_similarity(word1, word2)

# Recherche de mots-clÃ©s similaires
similar = core.find_similar_keywords(
    keyword,
    min_similarity=0.5,
    max_results=10
)

# Analyse de groupe
analysis = core.analyze_keyword_group(
    keywords,
    min_similarity=0.5
)
```

### Utils API

```python
# Cache
cache = CacheManager('./cache')
cache.set(key, value)
cached = cache.get(key)

# Formatage
safe_name = safe_filename(text)
formatted = format_number(1234)
```

## ğŸ§ª Tests

### Tests unitaires
```bash
python -m pytest tests/
```

### Tests de performance
```python
with Timer("Analyse"):
    results = core.analyze_keyword_group(keywords)
```

## ğŸš€ Performance

### Optimisations
- Cache vectoriel en mÃ©moire
- Traitement parallÃ¨le des calculs
- Mise en cache des rÃ©sultats intermÃ©diaires
- Gestion efficace de la mÃ©moire

### MÃ©triques
- Temps de chargement : ~2s/1000 mots-clÃ©s
- Utilisation mÃ©moire : ~100MB base + 1MB/1000 mots-clÃ©s
- Cache disque : ~50MB/10000 vecteurs

## â“ FAQ

**Q: Quelle taille de donnÃ©es maximale ?**
R: TestÃ© jusqu'Ã  100,000 mots-clÃ©s avec 16GB RAM.

**Q: Format d'import supportÃ© ?**
R: CSV avec colonnes 'keyword' et 'volume' obligatoires.

**Q: Temps de traitement ?**
R: Environ 2-3 secondes pour 1000 mots-clÃ©s aprÃ¨s le cache initial.

## ğŸ¤ Contribution

### Guidelines
1. Fork du projet
2. CrÃ©ez une branche (`git checkout -b feature/amelioration`)
3. Commit (`git commit -am 'Ajout fonctionnalitÃ©'`)
4. Push (`git push origin feature/amelioration`)
5. Pull Request

### Style de code
- Black pour le formatage
- Type hints obligatoires
- Docstrings format Google
- Tests unitaires requis

## ğŸ“„ Licence

MIT License

Copyright (c) 2024 Votre Nom

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software...

---

## ğŸ“Š Captures d'Ã©cran

[Ajoutez des captures d'Ã©cran de l'interface ici]

## ğŸ“ Support

- Issues GitHub
- Documentation : [lien]
- Email : votre@email.com

## ğŸ”„ Mises Ã  jour

### v1.0.0 (2024-03-03)
- Version initiale
- Interface Streamlit
- Analyse sÃ©mantique
- Export JSON
